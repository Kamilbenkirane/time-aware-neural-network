{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population Fitness Evaluation\n",
    "\n",
    "Evaluates multiple neural network individuals on a single trading epoch. Demonstrates population-level analysis and prepares for genetic algorithm operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Configuration\n",
    "\n",
    "**Modify these parameters to experiment with different setups:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# üîß CONFIGURATION - Modify these network\n",
    "POPULATION_SIZE = 100\n",
    "LAYER_SIZES = [1, 100, 200, 3]  # Input -> Hidden1 -> Hidden2 -> Output\n",
    "ACTIVATIONS = [1, 1, 2]         # [ReLU, ReLU, Sigmoid]\n",
    "EPOCH_ID = 1                    # Which epoch to analyze\n",
    "RANDOM_SEED = 42                # For reproducibility\n",
    "\n",
    "# üìù Architecture Options:\n",
    "# Small:  [1, 20, 10, 3]\n",
    "# Medium: [1, 50, 100, 3] \n",
    "# Large:  [1, 200, 400, 200, 3]\n",
    "# Deep:   [1, 50, 50, 50, 50, 3]\n",
    "\n",
    "# üéØ Activation Functions:\n",
    "# 0 = Linear\n",
    "# 1 = ReLU\n",
    "# 2 = Sigmoid  \n",
    "# 3 = Tanh\n",
    "\n",
    "print(f\"üìä Configuration:\")\n",
    "print(f\"   Population size: {POPULATION_SIZE}\")\n",
    "print(f\"   Architecture: {' -> '.join(map(str, LAYER_SIZES))}\")\n",
    "print(f\"   Activations: {ACTIVATIONS}\")\n",
    "print(f\"   Target epoch: {EPOCH_ID}\")\n",
    "print(f\"   Random seed: {RANDOM_SEED}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import numba_ga\n",
    "\n",
    "# Import population fitness functions\n",
    "sys.path.append('../../src/fitnesses')\n",
    "from fitness import evaluate_population_fitness_relative, evaluate_individual_fitness_relative"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Architecture Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert to numpy arrays for numba compatibility\n",
    "layer_sizes = np.array(LAYER_SIZES, dtype=np.int64)\n",
    "activations = np.array(ACTIVATIONS, dtype=np.int64)\n",
    "\n",
    "# Calculate architecture properties\n",
    "total_params = numba_ga.get_total_parameters(layer_sizes)\n",
    "activation_names = [numba_ga.get_activation_name(a) for a in activations]\n",
    "\n",
    "print(f\"üß† Network Architecture Analysis:\")\n",
    "print(f\"   Layers: {len(layer_sizes)}\")\n",
    "print(f\"   Architecture: {' -> '.join(map(str, layer_sizes))}\")\n",
    "print(f\"   Activations: {' -> '.join(activation_names)}\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Memory per individual: ~{total_params * 8 / 1024:.1f} KB\")\n",
    "print(f\"   Population memory: ~{total_params * 8 * POPULATION_SIZE / (1024*1024):.1f} MB\")\n",
    "\n",
    "# Estimate complexity\n",
    "complexity_score = total_params * POPULATION_SIZE\n",
    "if complexity_score < 100_000:\n",
    "    complexity = \"Low - Very fast evaluation\"\n",
    "elif complexity_score < 1_000_000:\n",
    "    complexity = \"Medium - Fast evaluation\"\n",
    "elif complexity_score < 10_000_000:\n",
    "    complexity = \"High - Moderate evaluation time\"\n",
    "else:\n",
    "    complexity = \"Very High - Slower evaluation\"\n",
    "\n",
    "print(f\"   Complexity: {complexity}\")\n",
    "print(f\"   Complexity score: {complexity_score:,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Epoch Selection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load processed data with epochs\n",
    "df = pl.read_parquet('../../data/mock_processed.parquet')\n",
    "\n",
    "print(f\"üìä Dataset Overview:\")\n",
    "print(f\"   Total shape: {df.shape}\")\n",
    "print(f\"   Available epochs: {df['epoch_id'].min()} - {df['epoch_id'].max()}\")\n",
    "\n",
    "# Extract target epoch\n",
    "epoch_data = df.filter(pl.col('epoch_id') == EPOCH_ID).sort('timestamp')\n",
    "\n",
    "if len(epoch_data) == 0:\n",
    "    print(f\"‚ùå Error: Epoch {EPOCH_ID} not found. Available epochs: {sorted(df['epoch_id'].unique().to_list())}\")\n",
    "    raise ValueError(f\"Invalid epoch ID: {EPOCH_ID}\")\n",
    "\n",
    "print(f\"\\nüïê Epoch {EPOCH_ID} Characteristics:\")\n",
    "print(f\"   Number of ticks: {len(epoch_data):,}\")\n",
    "print(f\"   Time range: {epoch_data['timestamp'].min():.1f} - {epoch_data['timestamp'].max():.1f} seconds\")\n",
    "print(f\"   Duration: {(epoch_data['timestamp'].max() - epoch_data['timestamp'].min()) / 60:.1f} minutes\")\n",
    "print(f\"   Price range: ${epoch_data['price'].min():.2f} - ${epoch_data['price'].max():.2f}\")\n",
    "print(f\"   Price change: {((epoch_data['price'][-1] - epoch_data['price'][0]) / epoch_data['price'][0] * 100):.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize the selected epoch\n",
    "timestamps = epoch_data['timestamp'].to_numpy()\n",
    "prices = epoch_data['price'].to_numpy()\n",
    "time_minutes = (timestamps - timestamps[0]) / 60\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=time_minutes,\n",
    "        y=prices,\n",
    "        mode='lines',\n",
    "        name=f'Epoch {EPOCH_ID} Price',\n",
    "        line=dict(color='blue', width=1.5)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Epoch {EPOCH_ID}: Price Time Series ({len(epoch_data):,} ticks over {time_minutes[-1]:.1f} minutes)\",\n",
    "    xaxis_title=\"Time (minutes from epoch start)\",\n",
    "    yaxis_title=\"Price ($)\",\n",
    "    width=800, height=400,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"üìà Trading Environment:\")\n",
    "print(f\"   Starting price: ${prices[0]:.2f}\")\n",
    "print(f\"   Ending price: ${prices[-1]:.2f}\")\n",
    "print(f\"   Buy-and-hold return: {((prices[-1] - prices[0]) / prices[0] * 100):.2f}%\")\n",
    "print(f\"   Price volatility: {np.std(prices):.2f}\")\n",
    "print(f\"   Number of opportunities: {len(prices):,} decision points\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Population Initialization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"üß¨ Initializing population of {POPULATION_SIZE} individuals...\")\n",
    "\n",
    "# Initialize population with configured network\n",
    "population = numba_ga.initialize_population(POPULATION_SIZE, layer_sizes, seed=RANDOM_SEED)\n",
    "\n",
    "print(f\"\\nüë• Population Properties:\")\n",
    "print(f\"   Shape: {population.shape}\")\n",
    "print(f\"   Memory usage: {population.nbytes / (1024*1024):.2f} MB\")\n",
    "print(f\"   Data type: {population.dtype}\")\n",
    "\n",
    "# Population diversity analysis\n",
    "all_weights = population.flatten()\n",
    "print(f\"\\nüìä Weight Distribution Across Population:\")\n",
    "print(f\"   Total weights: {len(all_weights):,}\")\n",
    "print(f\"   Mean: {np.mean(all_weights):.6f}\")\n",
    "print(f\"   Std: {np.std(all_weights):.6f}\")\n",
    "print(f\"   Range: {np.min(all_weights):.3f} to {np.max(all_weights):.3f}\")\n",
    "\n",
    "# Check population diversity (no identical individuals)\n",
    "unique_individuals = len(np.unique(population, axis=0))\n",
    "print(f\"\\nüé≤ Population Diversity:\")\n",
    "print(f\"   Unique individuals: {unique_individuals}/{POPULATION_SIZE}\")\n",
    "print(f\"   Diversity: {'Perfect ‚úÖ' if unique_individuals == POPULATION_SIZE else 'Duplicates found ‚ùå'}\")\n",
    "\n",
    "# Sample individual analysis\n",
    "sample_individual = population[0]\n",
    "print(f\"\\nüîç Sample Individual (ID 0):\")\n",
    "print(f\"   Parameters: {len(sample_individual):,}\")\n",
    "print(f\"   Weight range: {np.min(sample_individual):.3f} to {np.max(sample_individual):.3f}\")\n",
    "print(f\"   Mean: {np.mean(sample_individual):.6f}\")\n",
    "print(f\"   Std: {np.std(sample_individual):.6f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Population Fitness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"üöÄ Evaluating {POPULATION_SIZE} individuals on Epoch {EPOCH_ID}...\")\n",
    "print(f\"   Processing {len(timestamps):,} time steps per individual\")\n",
    "print(f\"   Total evaluations: {POPULATION_SIZE * len(timestamps):,}\")\n",
    "\n",
    "# Warm up the JIT compilation\n",
    "print(f\"\\n‚ö° Warming up JIT compilation...\")\n",
    "small_pop = population[:5]  # Use small subset for warmup\n",
    "_ = evaluate_population_fitness_relative(small_pop, layer_sizes, activations, timestamps, prices)\n",
    "print(f\"   JIT compilation complete ‚úÖ\")\n",
    "\n",
    "# Full population evaluation with timing\n",
    "print(f\"\\nüìä Running full population evaluation...\")\n",
    "start_time = time.time()\n",
    "\n",
    "fitness_scores = evaluate_population_fitness_relative(\n",
    "    population, layer_sizes, activations, timestamps, prices\n",
    ")\n",
    "\n",
    "evaluation_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Performance Results:\")\n",
    "print(f\"   Evaluation time: {evaluation_time:.3f} seconds\")\n",
    "print(f\"   Individuals per second: {POPULATION_SIZE / evaluation_time:.1f}\")\n",
    "print(f\"   Time per individual: {evaluation_time / POPULATION_SIZE * 1000:.2f} ms\")\n",
    "print(f\"   Evaluations per second: {(POPULATION_SIZE * len(timestamps)) / evaluation_time:,.0f}\")\n",
    "\n",
    "print(f\"\\nüí∞ Fitness Results:\")\n",
    "print(f\"   Fitness array shape: {fitness_scores.shape}\")\n",
    "print(f\"   Best fitness: {np.max(fitness_scores):.4f}\")\n",
    "print(f\"   Worst fitness: {np.min(fitness_scores):.4f}\")\n",
    "print(f\"   Mean fitness: {np.mean(fitness_scores):.4f}\")\n",
    "print(f\"   Median fitness: {np.median(fitness_scores):.4f}\")\n",
    "print(f\"   Std deviation: {np.std(fitness_scores):.4f}\")\n",
    "\n",
    "# Convert to returns for easier interpretation\n",
    "returns = (fitness_scores - 1.0) * 100\n",
    "print(f\"\\nüìà Return Analysis:\")\n",
    "print(f\"   Best return: {np.max(returns):.2f}%\")\n",
    "print(f\"   Worst return: {np.min(returns):.2f}%\")\n",
    "print(f\"   Mean return: {np.mean(returns):.2f}%\")\n",
    "print(f\"   Profitable individuals: {np.sum(returns > 0)}/{POPULATION_SIZE} ({np.sum(returns > 0)/POPULATION_SIZE*100:.1f}%)\")\n",
    "\n",
    "# Buy-and-hold benchmark\n",
    "buy_hold_return = ((prices[-1] - prices[0]) / prices[0]) * 100\n",
    "beat_market = np.sum(returns > buy_hold_return)\n",
    "print(f\"   Beat buy-and-hold ({buy_hold_return:.2f}%): {beat_market}/{POPULATION_SIZE} ({beat_market/POPULATION_SIZE*100:.1f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fitness Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create fitness distribution visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[\n",
    "        'Fitness Distribution (Portfolio Values)',\n",
    "        'Return Distribution (%)',\n",
    "        'Fitness vs Individual ID',\n",
    "        'Top 10 vs Bottom 10 Performers'\n",
    "    ],\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# 1. Fitness histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=fitness_scores,\n",
    "        nbinsx=30,\n",
    "        name='Fitness',\n",
    "        marker_color='blue',\n",
    "        opacity=0.7\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add vertical line at 1.0 (break-even)\n",
    "fig.add_vline(x=1.0, line_dash=\"dash\", line_color=\"red\", row=1, col=1)\n",
    "\n",
    "# 2. Returns histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=returns,\n",
    "        nbinsx=30,\n",
    "        name='Returns',\n",
    "        marker_color='green',\n",
    "        opacity=0.7\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Add vertical lines at 0% and buy-hold return\n",
    "fig.add_vline(x=0, line_dash=\"dash\", line_color=\"red\", row=1, col=2)\n",
    "fig.add_vline(x=buy_hold_return, line_dash=\"dot\", line_color=\"orange\", row=1, col=2)\n",
    "\n",
    "# 3. Fitness scatter plot\n",
    "individual_ids = np.arange(POPULATION_SIZE)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=individual_ids,\n",
    "        y=fitness_scores,\n",
    "        mode='markers',\n",
    "        name='Individual Fitness',\n",
    "        marker=dict(color=fitness_scores, colorscale='RdYlGn', size=4)\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Add horizontal line at 1.0\n",
    "fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"red\", row=2, col=1)\n",
    "\n",
    "# 4. Top vs Bottom performers\n",
    "sorted_indices = np.argsort(fitness_scores)\n",
    "top_10 = sorted_indices[-10:]\n",
    "bottom_10 = sorted_indices[:10]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(10)),\n",
    "        y=fitness_scores[bottom_10],\n",
    "        mode='markers+lines',\n",
    "        name='Bottom 10',\n",
    "        marker=dict(color='red', size=6),\n",
    "        line=dict(color='red')\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(10)),\n",
    "        y=fitness_scores[top_10],\n",
    "        mode='markers+lines',\n",
    "        name='Top 10',\n",
    "        marker=dict(color='green', size=6),\n",
    "        line=dict(color='green')\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_xaxes(title_text=\"Portfolio Value\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Return (%)\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Individual ID\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Rank\", row=2, col=2)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Count\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Portfolio Value\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Portfolio Value\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Population Fitness Analysis - {POPULATION_SIZE} Individuals on Epoch {EPOCH_ID}\",\n",
    "    height=800,\n",
    "    width=1000,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Individual Behavior Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Analyze top and bottom performers in detail\n",
    "sorted_indices = np.argsort(fitness_scores)\n",
    "best_individual_idx = sorted_indices[-1]\n",
    "worst_individual_idx = sorted_indices[0]\n",
    "median_individual_idx = sorted_indices[len(sorted_indices)//2]\n",
    "\n",
    "print(f\"üèÜ Performance Rankings:\")\n",
    "print(f\"   Best individual: #{best_individual_idx} (fitness: {fitness_scores[best_individual_idx]:.4f}, return: {(fitness_scores[best_individual_idx]-1)*100:.2f}%)\")\n",
    "print(f\"   Median individual: #{median_individual_idx} (fitness: {fitness_scores[median_individual_idx]:.4f}, return: {(fitness_scores[median_individual_idx]-1)*100:.2f}%)\")\n",
    "print(f\"   Worst individual: #{worst_individual_idx} (fitness: {fitness_scores[worst_individual_idx]:.4f}, return: {(fitness_scores[worst_individual_idx]-1)*100:.2f}%)\")\n",
    "\n",
    "# Function to analyze individual trading behavior\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def analyze_individual_behavior(parameters, layer_sizes, activations, timestamps, prices):\n",
    "    \"\"\"Returns detailed trading analysis for visualization.\"\"\"\n",
    "    # Pre-compute shared data\n",
    "    param_indices, neuron_indices = numba_ga.compute_layer_indices(layer_sizes)\n",
    "    prices_normalized = prices / prices[0]\n",
    "    \n",
    "    # Arrays to track behavior\n",
    "    actions = np.zeros(len(timestamps), dtype=np.int64)\n",
    "    network_outputs = np.zeros((len(timestamps), 3), dtype=np.float64)\n",
    "    portfolio_history = np.zeros(len(timestamps), dtype=np.float64)\n",
    "    \n",
    "    # Network state\n",
    "    input_buffer = np.zeros(1, dtype=np.float64)\n",
    "    current_states = np.zeros(np.sum(layer_sizes[1:]), dtype=np.float64)\n",
    "    current_time = 0.0\n",
    "    \n",
    "    # Trading state\n",
    "    position = 0\n",
    "    buy_price_norm = 0.0\n",
    "    portfolio_value = 1.0\n",
    "    \n",
    "    # Main loop\n",
    "    for i in range(len(timestamps)):\n",
    "        input_buffer[0] = prices_normalized[i]\n",
    "        inputs = (timestamps[i], input_buffer)\n",
    "        \n",
    "        output, new_states, new_time = numba_ga.predict_individual(\n",
    "            parameters, layer_sizes, activations, inputs,\n",
    "            current_states, current_time, param_indices, neuron_indices\n",
    "        )\n",
    "        \n",
    "        network_outputs[i] = output\n",
    "        \n",
    "        action = (0 if output[0] >= output[1] and output[0] >= output[2] \n",
    "                 else 1 if output[1] >= output[2] else 2)\n",
    "        \n",
    "        # Trading logic\n",
    "        if position == 0 and action == 2:\n",
    "            position = 1\n",
    "            buy_price_norm = prices_normalized[i]\n",
    "            actual_action = 2  # BUY\n",
    "        elif position == 1 and action == 0:\n",
    "            sell_price_norm = prices_normalized[i]\n",
    "            portfolio_value *= (sell_price_norm / buy_price_norm)\n",
    "            position = 0\n",
    "            actual_action = 0  # SELL\n",
    "        else:\n",
    "            actual_action = 1  # HOLD\n",
    "        \n",
    "        actions[i] = actual_action\n",
    "        portfolio_history[i] = portfolio_value\n",
    "        \n",
    "        current_states = new_states\n",
    "        current_time = new_time\n",
    "    \n",
    "    # Close position if holding at end\n",
    "    if position == 1:\n",
    "        final_price_norm = prices_normalized[-1]\n",
    "        portfolio_value *= (final_price_norm / buy_price_norm)\n",
    "        portfolio_history[-1] = portfolio_value\n",
    "    \n",
    "    return actions, network_outputs, portfolio_history\n",
    "\n",
    "# Analyze the three key individuals\n",
    "individuals_to_analyze = [\n",
    "    (best_individual_idx, \"Best\", \"green\"),\n",
    "    (median_individual_idx, \"Median\", \"orange\"), \n",
    "    (worst_individual_idx, \"Worst\", \"red\")\n",
    "]\n",
    "\n",
    "analysis_results = {}\n",
    "for idx, label, color in individuals_to_analyze:\n",
    "    actions, outputs, portfolio = analyze_individual_behavior(\n",
    "        population[idx], layer_sizes, activations, timestamps, prices\n",
    "    )\n",
    "    analysis_results[label] = {\n",
    "        'idx': idx,\n",
    "        'actions': actions,\n",
    "        'outputs': outputs, \n",
    "        'portfolio': portfolio,\n",
    "        'color': color,\n",
    "        'fitness': fitness_scores[idx]\n",
    "    }\n",
    "\n",
    "print(f\"\\nüîç Behavioral Analysis Complete\")\n",
    "for label, data in analysis_results.items():\n",
    "    action_counts = np.bincount(data['actions'], minlength=3)\n",
    "    num_trades = action_counts[0] + action_counts[2]\n",
    "    print(f\"   {label} (#{data['idx']}): {num_trades} trades, final value: {data['fitness']:.4f}\")\n",
    "    print(f\"     Actions: {action_counts[0]} sells, {action_counts[1]} holds, {action_counts[2]} buys\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize individual behaviors\n",
    "fig = make_subplots(\n",
    "    rows=4, cols=1,\n",
    "    subplot_titles=[\n",
    "        'Price Evolution with Trading Actions',\n",
    "        'Network Outputs (Sell/Hold/Buy Signals)',\n",
    "        'Actual Actions Taken',\n",
    "        'Portfolio Value Evolution'\n",
    "    ],\n",
    "    vertical_spacing=0.08,\n",
    "    specs=[[{\"secondary_y\": False}]] * 4\n",
    ")\n",
    "\n",
    "time_minutes = (timestamps - timestamps[0]) / 60\n",
    "\n",
    "# 1. Price with trading markers\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=time_minutes,\n",
    "        y=prices,\n",
    "        mode='lines',\n",
    "        name='Price',\n",
    "        line=dict(color='blue', width=1.5),\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add trading actions for each individual\n",
    "for label, data in analysis_results.items():\n",
    "    buy_mask = data['actions'] == 2\n",
    "    sell_mask = data['actions'] == 0\n",
    "    \n",
    "    if np.any(buy_mask):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=time_minutes[buy_mask],\n",
    "                y=prices[buy_mask],\n",
    "                mode='markers',\n",
    "                name=f'{label} BUY',\n",
    "                marker=dict(color=data['color'], size=6, symbol='triangle-up')\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    if np.any(sell_mask):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=time_minutes[sell_mask],\n",
    "                y=prices[sell_mask],\n",
    "                mode='markers',\n",
    "                name=f'{label} SELL',\n",
    "                marker=dict(color=data['color'], size=6, symbol='triangle-down')\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "# 2. Network outputs (show only best individual to avoid clutter)\n",
    "best_data = analysis_results['Best']\n",
    "output_names = ['Sell Signal', 'Hold Signal', 'Buy Signal']\n",
    "output_colors = ['red', 'gray', 'green']\n",
    "\n",
    "for i in range(3):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=time_minutes,\n",
    "            y=best_data['outputs'][:, i],\n",
    "            mode='lines',\n",
    "            name=f'Best: {output_names[i]}',\n",
    "            line=dict(color=output_colors[i], width=1),\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# 3. Actions comparison\n",
    "for label, data in analysis_results.items():\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=time_minutes,\n",
    "            y=data['actions'],\n",
    "            mode='markers',\n",
    "            name=f'{label} Actions',\n",
    "            marker=dict(color=data['color'], size=2),\n",
    "            opacity=0.6\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "# 4. Portfolio evolution\n",
    "for label, data in analysis_results.items():\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=time_minutes,\n",
    "            y=data['portfolio'],\n",
    "            mode='lines',\n",
    "            name=f'{label} Portfolio',\n",
    "            line=dict(color=data['color'], width=2)\n",
    "        ),\n",
    "        row=4, col=1\n",
    "    )\n",
    "\n",
    "# Add break-even line\n",
    "fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"black\", opacity=0.5, row=4, col=1)\n",
    "\n",
    "# Update layout\n",
    "fig.update_xaxes(title_text=\"Time (minutes)\", row=4, col=1)\n",
    "fig.update_yaxes(title_text=\"Price ($)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Output Value\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Action\", row=3, col=1, tickvals=[0, 1, 2], ticktext=['SELL', 'HOLD', 'BUY'])\n",
    "fig.update_yaxes(title_text=\"Portfolio Value\", row=4, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Individual Behavior Comparison - Best vs Median vs Worst Performers\",\n",
    "    height=1200,\n",
    "    width=1000,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Scaling Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test different population sizes to show scaling\n",
    "test_sizes = [10, 25, 50, 100, 200] if POPULATION_SIZE >= 200 else [10, 25, 50, 100]\n",
    "if POPULATION_SIZE not in test_sizes:\n",
    "    test_sizes.append(POPULATION_SIZE)\n",
    "test_sizes = sorted(test_sizes)\n",
    "\n",
    "print(f\"‚ö° Performance Scaling Analysis\")\n",
    "print(f\"   Testing population sizes: {test_sizes}\")\n",
    "print(f\"   Architecture: {' -> '.join(map(str, LAYER_SIZES))}\")\n",
    "\n",
    "scaling_results = []\n",
    "\n",
    "for size in test_sizes:\n",
    "    if size <= POPULATION_SIZE:\n",
    "        # Use subset of current population\n",
    "        test_pop = population[:size]\n",
    "    else:\n",
    "        # Generate larger population\n",
    "        test_pop = numba_ga.initialize_population(size, layer_sizes, seed=RANDOM_SEED)\n",
    "    \n",
    "    # Warm up for this size (first run always slower)\n",
    "    _ = evaluate_population_fitness_relative(test_pop[:min(5, size)], layer_sizes, activations, timestamps, prices)\n",
    "    \n",
    "    # Time the evaluation\n",
    "    start_time = time.time()\n",
    "    test_fitness = evaluate_population_fitness_relative(test_pop, layer_sizes, activations, timestamps, prices)\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate metrics\n",
    "    individuals_per_sec = size / eval_time\n",
    "    time_per_individual = eval_time / size * 1000  # milliseconds\n",
    "    \n",
    "    scaling_results.append({\n",
    "        'size': size,\n",
    "        'time': eval_time,\n",
    "        'ind_per_sec': individuals_per_sec,\n",
    "        'ms_per_ind': time_per_individual,\n",
    "        'best_fitness': np.max(test_fitness),\n",
    "        'mean_fitness': np.mean(test_fitness)\n",
    "    })\n",
    "    \n",
    "    print(f\"   Size {size:3d}: {eval_time:.3f}s ({individuals_per_sec:.1f} ind/s, {time_per_individual:.2f} ms/ind)\")\n",
    "\n",
    "# Analyze scaling efficiency\n",
    "print(f\"\\nüìä Scaling Efficiency:\")\n",
    "baseline_time_per_ind = scaling_results[0]['ms_per_ind']\n",
    "for result in scaling_results:\n",
    "    efficiency = baseline_time_per_ind / result['ms_per_ind'] * 100\n",
    "    print(f\"   Size {result['size']:3d}: {efficiency:.1f}% efficient (vs size {test_sizes[0]})\")\n",
    "\n",
    "# Memory scaling\n",
    "print(f\"\\nüíæ Memory Usage Scaling:\")\n",
    "for result in scaling_results:\n",
    "    memory_mb = total_params * 8 * result['size'] / (1024*1024)\n",
    "    print(f\"   Size {result['size']:3d}: ~{memory_mb:.1f} MB\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize scaling performance\n",
    "sizes = [r['size'] for r in scaling_results]\n",
    "times = [r['time'] for r in scaling_results]\n",
    "ind_per_sec = [r['ind_per_sec'] for r in scaling_results]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['Evaluation Time vs Population Size', 'Throughput vs Population Size']\n",
    ")\n",
    "\n",
    "# Linear and ideal scaling reference lines\n",
    "ideal_times = [times[0] * (s / sizes[0]) for s in sizes]\n",
    "ideal_throughput = [ind_per_sec[0] for _ in sizes]  # Should stay constant\n",
    "\n",
    "# Plot 1: Evaluation time\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=sizes,\n",
    "        y=times,\n",
    "        mode='markers+lines',\n",
    "        name='Actual Time',\n",
    "        marker=dict(color='blue', size=8),\n",
    "        line=dict(color='blue')\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=sizes,\n",
    "        y=ideal_times,\n",
    "        mode='lines',\n",
    "        name='Ideal Linear',\n",
    "        line=dict(color='gray', dash='dash')\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Throughput\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=sizes,\n",
    "        y=ind_per_sec,\n",
    "        mode='markers+lines',\n",
    "        name='Actual Throughput',\n",
    "        marker=dict(color='green', size=8),\n",
    "        line=dict(color='green')\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=sizes,\n",
    "        y=ideal_throughput,\n",
    "        mode='lines',\n",
    "        name='Ideal Constant',\n",
    "        line=dict(color='gray', dash='dash')\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Population Size\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Population Size\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Time (seconds)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Individuals/Second\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Population Fitness Evaluation - Performance Scaling\",\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Calculate parallel efficiency\n",
    "if len(scaling_results) >= 2:\n",
    "    parallel_efficiency = (scaling_results[0]['ind_per_sec'] / scaling_results[-1]['ind_per_sec']) * 100\n",
    "    print(f\"\\n‚ö° Parallel Efficiency: {parallel_efficiency:.1f}%\")\n",
    "    print(f\"   (Higher is better - 100% means perfect scaling)\")\n",
    "    \n",
    "    if parallel_efficiency > 90:\n",
    "        print(f\"   üéØ Excellent scaling - Numba parallel optimization working well!\")\n",
    "    elif parallel_efficiency > 70:\n",
    "        print(f\"   ‚úÖ Good scaling - Minor overhead but efficient\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Scaling issues - May need optimization for large populations\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"üìä POPULATION FITNESS EVALUATION SUMMARY\")\n",
    "print(f\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüîß Configuration Used:\")\n",
    "print(f\"   Population size: {POPULATION_SIZE}\")\n",
    "print(f\"   Architecture: {' -> '.join(map(str, LAYER_SIZES))}\")\n",
    "print(f\"   Activations: {' -> '.join([numba_ga.get_activation_name(a) for a in activations])}\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Epoch analyzed: {EPOCH_ID}\")\n",
    "\n",
    "print(f\"\\nüí∞ Financial Results:\")\n",
    "print(f\"   Best performer: {np.max(returns):.2f}% return\")\n",
    "print(f\"   Worst performer: {np.min(returns):.2f}% return\")\n",
    "print(f\"   Population mean: {np.mean(returns):.2f}% return\")\n",
    "print(f\"   Profitable traders: {np.sum(returns > 0)}/{POPULATION_SIZE} ({np.sum(returns > 0)/POPULATION_SIZE*100:.1f}%)\")\n",
    "print(f\"   Beat market: {beat_market}/{POPULATION_SIZE} ({beat_market/POPULATION_SIZE*100:.1f}%)\")\n",
    "print(f\"   Market return: {buy_hold_return:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚ö° Performance Metrics:\")\n",
    "print(f\"   Evaluation time: {evaluation_time:.3f} seconds\")\n",
    "print(f\"   Throughput: {POPULATION_SIZE / evaluation_time:.1f} individuals/second\")\n",
    "print(f\"   Time per individual: {evaluation_time / POPULATION_SIZE * 1000:.2f} ms\")\n",
    "print(f\"   Total decisions: {POPULATION_SIZE * len(timestamps):,}\")\n",
    "\n",
    "print(f\"\\nüß¨ Population Insights:\")\n",
    "fitness_range = np.max(fitness_scores) - np.min(fitness_scores)\n",
    "print(f\"   Fitness diversity: {fitness_range:.4f} (range of outcomes)\")\n",
    "print(f\"   Std deviation: {np.std(fitness_scores):.4f}\")\n",
    "print(f\"   Perfect diversity: {'‚úÖ' if unique_individuals == POPULATION_SIZE else '‚ùå'}\")\n",
    "\n",
    "# Trading behavior summary\n",
    "total_actions = {}\n",
    "for label, data in analysis_results.items():\n",
    "    action_counts = np.bincount(data['actions'], minlength=3)\n",
    "    total_actions[label] = action_counts\n",
    "\n",
    "print(f\"\\nüéØ Trading Behavior (Top 3 Analyzed):\")\n",
    "for label, counts in total_actions.items():\n",
    "    total_trades = counts[0] + counts[2]\n",
    "    activity_rate = total_trades / len(timestamps) * 100\n",
    "    print(f\"   {label}: {total_trades} trades ({activity_rate:.2f}% activity rate)\")\n",
    "\n",
    "print(f\"\\nüöÄ Ready for Genetic Algorithm:\")\n",
    "print(f\"   ‚úÖ Population initialization working\")\n",
    "print(f\"   ‚úÖ Fitness evaluation optimized\")\n",
    "print(f\"   ‚úÖ Performance scaling verified\")\n",
    "print(f\"   ‚úÖ Individual behavior analysis ready\")\n",
    "print(f\"   ‚úÖ Fitness diversity for selection\")\n",
    "\n",
    "print(f\"\\nüìà Next Steps:\")\n",
    "print(f\"   1. Multi-epoch evaluation (test consistency)\")\n",
    "print(f\"   2. Tournament selection (choose parents)\")\n",
    "print(f\"   3. Crossover operations (breed new individuals)\")\n",
    "print(f\"   4. Mutation operations (add diversity)\")\n",
    "print(f\"   5. Evolutionary loop (improve over generations)\")\n",
    "\n",
    "print(f\"\\n‚úÖ POPULATION FITNESS EVALUATION COMPLETE!\")\n",
    "print(f\"   üéØ Foundation established for genetic algorithm evolution\")\n",
    "print(f\"   üìä Population shows diverse trading strategies\")\n",
    "print(f\"   ‚ö° Performance optimized for large-scale evolution\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
